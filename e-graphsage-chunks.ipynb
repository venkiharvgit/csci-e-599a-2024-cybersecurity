{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jr_Usb4um62a",
    "outputId": "2d359c9b-fd15-4ff2-b8e5-7303de7938d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.dgl.ai/wheels/cu121/repo.html\n",
      "Collecting dgl\n",
      "  Downloading https://data.dgl.ai/wheels/cu121/dgl-2.0.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (926.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.0/926.0 MB\u001b[0m \u001b[31m925.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata>=0.5.0->dgl) (1.3.0)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-2.0.0+cu121\n",
      "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
      "Collecting dglgo\n",
      "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m496.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.9.0)\n",
      "Collecting isort>=5.10.1 (from dglgo)\n",
      "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
      "  Downloading autopep8-2.0.4-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
      "  Downloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (2.6.1)\n",
      "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0.1)\n",
      "Collecting ogb>=1.3.3 (from dglgo)\n",
      "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
      "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
      "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
      "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
      "Requirement already satisfied: sphinx>=5 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (5.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.3)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.1.0+cu121)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.25.2)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.7)\n",
      "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
      "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.9.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.5)\n",
      "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
      "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.4)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.8)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.6)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.7)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\n",
      "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.18.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.7.16)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (23.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
      "Building wheels for collected packages: littleutils\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=b7711fc5f18c142449b50f5d17b6c258dca770920fdc9c4cd5e150e20f4e0e14\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
      "Successfully built littleutils\n",
      "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, ruamel.yaml, outdated, autopep8, ogb, numpydoc, dglgo\n",
      "Successfully installed autopep8-2.0.4 dglgo-0.0.2 isort-5.13.2 littleutils-0.2.2 numpydoc-1.6.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.11.1 rdkit-pypi-2022.9.5 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install  dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
    "!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html\n",
    "\n",
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzQSn3iObSox",
    "outputId": "2aa1c08e-e625-42ef-a91d-0e607a632350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mS0bWISTqhMI",
    "outputId": "51836c2d-9c41-4ccd-bdd2-61c781bc4177",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammadli/miniconda3/envs/py_jop/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 13.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import struct\n",
    "import random\n",
    "import pathlib\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "from dgl import from_networkx\n",
    "from dgl.data.utils import save_graphs\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fBP9dONhaRu8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "        super(SAGELayer, self).__init__()\n",
    "        ### force to outut fix dimensions\n",
    "        self.W_msg = nn.Linear(ndim_in + edims, ndim_out)\n",
    "        ### apply weight\n",
    "        self.W_apply = nn.Linear(ndim_in + ndim_out, ndim_out)\n",
    "        self.activation = activation\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'m': self.W_msg(th.cat([edges.src['h'], edges.data['h']], 2))}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            g.ndata['h'] = nfeats\n",
    "            g.edata['h'] = efeats\n",
    "            # Eq4\n",
    "            g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "            # Eq5\n",
    "            g.ndata['h'] = F.relu(self.W_apply(th.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "            return g.ndata['h']\n",
    "\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(SAGELayer(ndim_in, edim, 128, activation))\n",
    "        self.layers.append(SAGELayer(128, edim, ndim_out, activation))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                nfeats = self.dropout(nfeats)\n",
    "            nfeats = layer(g, nfeats, efeats)\n",
    "        return nfeats.sum(1)\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(th.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super().__init__()\n",
    "        self.gnn = SAGE(ndim_in, ndim_out, edim, activation, dropout)\n",
    "        self.pred = MLPPredictor(ndim_out, 2)\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        h = self.gnn(g, nfeats, efeats)\n",
    "        return self.pred(g, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SX1H69nKaRu9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def correct_df(df, cols):\n",
    "\n",
    "    df = df[cols]\n",
    "    df['IPV4_SRC_ADDR'] = df.IPV4_SRC_ADDR.apply(lambda x: socket.inet_ntoa(struct.pack('>I', random.randint(0xac100001, 0xac1f0001))))\n",
    "    df['IPV4_SRC_ADDR'] = df.IPV4_SRC_ADDR.apply(str)\n",
    "    df['L4_SRC_PORT'] = df.L4_SRC_PORT.apply(str)\n",
    "    df['IPV4_DST_ADDR'] = df.IPV4_DST_ADDR.apply(str)\n",
    "    df['L4_DST_PORT'] = df.L4_DST_PORT.apply(str)\n",
    "    df['IPV4_SRC_ADDR'] = df['IPV4_SRC_ADDR'] + ':' + df['L4_SRC_PORT']\n",
    "    df['IPV4_DST_ADDR'] = df['IPV4_DST_ADDR'] + ':' + df['L4_DST_PORT']\n",
    "    df.drop(columns=['L4_SRC_PORT','L4_DST_PORT'], inplace=True)\n",
    "    df.rename(columns={\"Label\": \"label\"},inplace = True)\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    label = df.label\n",
    "    df.drop(columns=['label'],inplace = True)\n",
    "    df = pd.concat([df, label], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def train_egraphsage(df_train, model, epochs, cuda, report_epochs):\n",
    "\n",
    "    print(\"Building a graph...\")\n",
    "    G = nx.from_pandas_edgelist(df_train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", ['h','label'],create_using=nx.MultiGraph())\n",
    "    G = G.to_directed()\n",
    "    G = from_networkx(G,edge_attrs=['h','label'] )\n",
    "\n",
    "    G.ndata['h'] = th.ones(G.num_nodes(), G.edata['h'].shape[1])\n",
    "    G.edata['train_mask'] = th.ones(len(G.edata['h']), dtype=th.bool)\n",
    "    G.ndata['h'] = th.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1,G.ndata['h'].shape[1]))\n",
    "    G.edata['h'] = th.reshape(G.edata['h'], (G.edata['h'].shape[0], 1,G.edata['h'].shape[1]))\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight(class_weight = \"balanced\",\n",
    "                                                      classes = np.unique(G.edata['label'].cpu().numpy()),\n",
    "                                                      y = G.edata['label'].cpu().numpy())\n",
    "\n",
    "    class_weights = th.FloatTensor(class_weights).cuda() if cuda else th.FloatTensor(class_weights)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    if cuda:\n",
    "        G = G.to('cuda:0')\n",
    "        model = model.cuda()\n",
    "\n",
    "    node_features = G.ndata['h']\n",
    "    edge_features = G.edata['h']\n",
    "\n",
    "    edge_label = G.edata['label']\n",
    "    train_mask = G.edata['train_mask']\n",
    "\n",
    "    opt = th.optim.Adam(model.parameters())\n",
    "\n",
    "    print(\"Training started...\")\n",
    "    for epoch in range(1,epochs+1):\n",
    "        pred = model(G, node_features,edge_features).cuda() if cuda else model(G, node_features,edge_features)\n",
    "        loss = criterion(pred[train_mask], edge_label[train_mask])\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch % report_epochs == 0:\n",
    "            print('Training acc',str(epoch),':', compute_accuracy(pred[train_mask], edge_label[train_mask]))\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_in_chunks(model, path, chunk_size, cols, epochs, cuda=False, report_epochs=100):\n",
    "\n",
    "    def extract_number(path):\n",
    "        return int(path.stem.split(\".\")[1])\n",
    "\n",
    "    files = sorted(pathlib.Path(path).glob(\"part.*.parquet\"), key=extract_number)\n",
    "\n",
    "    encoder = None\n",
    "    scaler = None\n",
    "    cols_to_norm = None\n",
    "\n",
    "    df_train = pd.DataFrame()\n",
    "    for path in files:\n",
    "\n",
    "        print(path)\n",
    "        df_chunk = correct_df(pd.read_parquet(path), cols)\n",
    "\n",
    "        if df_train.shape[0] < chunk_size:\n",
    "            df_train = pd.concat([df_train, df_chunk])\n",
    "        else:\n",
    "            if encoder == None:\n",
    "                encoder = ce.TargetEncoder(cols=['TCP_FLAGS','PROTOCOL'])\n",
    "                encoder.fit(df_train, df_train.label)\n",
    "            df_train = encoder.transform(df_train)\n",
    "\n",
    "            if scaler == None:\n",
    "                scaler = StandardScaler()\n",
    "                cols_to_norm = list(set(list(df_train.iloc[:, 2:].columns ))  - set(list(['label'])) )\n",
    "                df_train[cols_to_norm] = scaler.fit_transform(df_train[cols_to_norm])\n",
    "            df_train[cols_to_norm] = scaler.transform(df_train[cols_to_norm])\n",
    "\n",
    "            df_train['h'] = df_train[cols_to_norm].values.tolist()\n",
    "\n",
    "            model = train_egraphsage(df_train, model, epochs, cuda, report_epochs)\n",
    "\n",
    "            df_train = pd.DataFrame()\n",
    "\n",
    "\n",
    "    return model, encoder, scaler, cols_to_norm\n",
    "\n",
    "\n",
    "def predict_egraphsage(df_test, model, encoder, scaler, cols_to_norm):\n",
    "\n",
    "    df_test = encoder.transform(df_test)\n",
    "    df_test[cols_to_norm] = scaler.transform(df_test[cols_to_norm])\n",
    "    df_test['h'] = df_test[cols_to_norm].values.tolist()\n",
    "\n",
    "    G_test = nx.from_pandas_edgelist(df_test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", ['h','label'],create_using=nx.MultiGraph())\n",
    "    G_test = G_test.to_directed()\n",
    "    G_test = from_networkx(G_test,edge_attrs=['h','label'] )\n",
    "    actual = G_test.edata.pop('label')\n",
    "    G_test.ndata['feature'] = th.ones(G_test.num_nodes(), G.ndata['h'].shape[2])\n",
    "\n",
    "    G_test.ndata['feature'] = th.reshape(G_test.ndata['feature'], (G_test.ndata['feature'].shape[0], 1, G_test.ndata['feature'].shape[1]))\n",
    "\n",
    "    G_test.edata['h'] = th.reshape(G_test.edata['h'], (G_test.edata['h'].shape[0], 1, G_test.edata['h'].shape[1]))\n",
    "\n",
    "    node_features_test = G_test.ndata['feature']\n",
    "    edge_features_test = G_test.edata['h']\n",
    "    test_pred = model(G_test, node_features_test, edge_features_test)#.cuda()\n",
    "\n",
    "    test_pred = test_pred.argmax(1)\n",
    "\n",
    "    test_pred = th.Tensor.cpu(test_pred).detach().numpy()\n",
    "\n",
    "    return confusion_matrix(actual, test_pred), accuracy_score(actual, test_pred)\n",
    "\n",
    "def save_model(model, MODEL_PATH, scaler, SCALER_PATH, encoder, ENCODER_PATH):\n",
    "    th.save(model, MODEL_PATH)\n",
    "    joblib.dump(scaler, SCALER_PATH)\n",
    "    joblib.dump(encoder, ENCODER_PATH)\n",
    "\n",
    "def save_graph(G, GRAPH_PATH):\n",
    "    save_graphs(GRAPH_PATH, [G], None)\n",
    "\n",
    "def load_model(MODEL_PATH, SCALER_PATH, ENCODER_PATH):\n",
    "    model = th.load(MODEL_PATH)\n",
    "    model.eval()\n",
    "    scaler = joblib.load(SCALER_PATH)\n",
    "    encoder = joblib.load(ENCODER_PATH)\n",
    "\n",
    "    return model, scaler, encoder\n",
    "\n",
    "def load_graph(G, GRAPH_PATH):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XUIP8u7kaRu9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1E__R0BNZTs"
   },
   "source": [
    "**COLAB directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1L_B5XNNBU9"
   },
   "outputs": [],
   "source": [
    "dir_data = '/content/drive/MyDrive/csci_e-599a/data/'\n",
    "dir_model = '/content/drive/MyDrive/csci_e-599a/model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yno-iYAfNdO-"
   },
   "source": [
    "**Local directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HnMqGLOoNGkv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_data = '../data/netflow/parquet/original/'\n",
    "dir_model = 'model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puwbNRlbe-IV"
   },
   "source": [
    "**Train on 'NF-BoT-IoT-v2_chunks' in chunks...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jl92sOZGaRu-",
    "outputId": "1a7542b6-de5c-4172-a36a-673b52fa924b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.0.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.1.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.2.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.3.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.4.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.5.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.6.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.7.parquet\n",
      "../data/netflow/parquet/original/NF-BoT-IoT-v2_chunks/part.8.parquet\n",
      "Building a graph...\n",
      "Training started...\n",
      "Training acc 20 : 0.9568582773208618\n",
      "Training acc 40 : 0.9300925135612488\n"
     ]
    }
   ],
   "source": [
    "path = dir_data + 'NF-BoT-IoT-v2_chunks'\n",
    "\n",
    "cols = ['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'L4_SRC_PORT','L4_DST_PORT', 'PROTOCOL', 'IN_BYTES', 'OUT_BYTES',\n",
    "       'IN_PKTS', 'OUT_PKTS', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS','Label']\n",
    "\n",
    "n_features = len(cols) - 4 - 1 #'IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'L4_SRC_PORT','L4_DST_PORT', 'Label'\n",
    "model = Model(n_features, 128, n_features, F.relu, 0.2)\n",
    "\n",
    "chunk_size = 1000000\n",
    "epochs = 100\n",
    "cuda = False\n",
    "report_epochs = 20\n",
    "\n",
    "model, encoder, scaler, cols_to_norm = train_in_chunks(model, path, chunk_size, cols, epochs, cuda, report_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKZhQ209MBWC"
   },
   "source": [
    "**Save model, encoder and scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-j7AvIZaL_df",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH_BOT = dir_model + 'nf_bot_v2.pt'\n",
    "SCALER_PATH_BOT = dir_model + '_scaler_nf_bot_v2.pkl'\n",
    "ENCODER_PATH_BOT = dir_model + '_scaler_nf_bot_v2.pkl'\n",
    "\n",
    "save_model(model, MODEL_PATH_BOT, scaler, SCALER_PATH_BOT, encoder, ENCODER_PATH_BOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aER09c_fuJ3"
   },
   "source": [
    "**Train on 'NF-ToN-IoT_chunks' in chunks...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwEqxD-iaRu-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = dir_data + 'NF-ToN-IoT_chunks'\n",
    "\n",
    "model, encoder, scaler, cols_to_norm = train_in_chunks(model, path, chunk_size, cols, cuda, report_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPbakuy4f3F0"
   },
   "source": [
    "**Save model, encoder and scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdtuG1sZaRu-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH_BOT_TON = dir_model + 'nf_bot_v2_ton.pt'\n",
    "SCALER_PATH_BOT_TON = dir_model + '_scaler_nf_bot_v2_ton.pkl'\n",
    "ENCODER_PATH_BOT_TON = dir_model + '_scaler_nf_bot_v2_ton.pkl'\n",
    "\n",
    "save_model(model, MODEL_PATH_BOT_TON, scaler, SCALER_PATH_BOT_TON, encoder, ENCODER_PATH_BOT_TON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M74vlNYVOR9i"
   },
   "source": [
    "**Load test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dwdz-YjFOPnq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(dir_data + 'Attack-2_chunks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uicugV4Gf86-"
   },
   "source": [
    "**Load model, encoder, scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZifGr5lxaRu-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model, scaler, encoder = load_model(MODEL_PATH, SCALER_PATH, ENCODER_PATH)\n",
    "#cols_to_norm = list(set(list(df_test.iloc[:, 2:].columns ))  - set(list(['label'])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qyc60izOgZtU"
   },
   "source": [
    "**Test model on 'Attack-2_chunks'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pR_jcxQ2aRu-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm, acc = predict_egraphsage(df_test, model, encoder, scaler, cols_to_norm)\n",
    "\n",
    "print(\"Test results:\")\n",
    "print(cm)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
